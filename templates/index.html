<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AfricanVoice - Voice Translator</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max_width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        h1 { color: #2c3e50; }
        .controls { margin: 30px 0; }
        button {
            padding: 15px 30px;
            font-size: 18px;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
        }

        /* Professional theme toggle button */
        .theme-toggle {
            position: absolute;
            top: 18px;
            right: 18px;
            padding: 8px 12px;
            font-size: 13px;
            border-radius: 8px;
            border: 1px solid rgba(255,255,255,0.08);
            background: linear-gradient(180deg, rgba(255,255,255,0.03), rgba(0,0,0,0.08));
            color: #f1f5f9;
            box-shadow: 0 2px 6px rgba(2,6,23,0.4);
            cursor: pointer;
            transition: transform 0.12s ease, box-shadow 0.12s ease, opacity 0.12s ease;
        }
        .theme-toggle:hover { transform: translateY(-1px); opacity: 0.95; }
        .theme-toggle:active { transform: translateY(0); }
        .theme-toggle.light { background: #ffffff; color: #111827; border: 1px solid rgba(16,24,40,0.06); box-shadow: 0 2px 6px rgba(16,24,40,0.06); }
        #recordBtn {
            background-color: #e74c3c;
            color: white;
        }
        #recordBtn.recording {
            background-color: #c0392b;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        .dropzone {
            border: 3px dashed #3498db;
            border-radius: 15px;
            padding: 40px;
            margin: 20px 0;
            text-align: center;
            background-color: #f8f9fa;
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .dropzone:hover {
            background-color: #e3f2fd;
            border-color: #2980b9;
        }
        .dropzone.dragover {
            background-color: #d1ecf1;
            border-color: #0c5460;
            transform: scale(1.02);
        }
        .result-box {
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 10px;
            display: none;
        }
        .transcription {
            font-style: italic;
            color: #7f8c8d;
            margin-bottom: 15px;
        }
        .translation {
            font-size: 24px;
            font-weight: bold;
            color: #27ae60;
            margin-bottom: 15px;
        }
        .status {
            margin-top: 10px;
            color: #666;
        }
        /* Scrolling Text Styles */
        .scrolling-wrapper {
            overflow: hidden;
            white-space: nowrap;
            background-color: #e8f4f8;
            padding: 10px 0;
            margin: 15px 0;
            border-radius: 5px;
            border-left: 5px solid #3498db;
            display: flex;
        }
        .scrolling-text {
            animation: scroll 40s linear infinite;
            font-size: 16px;
            color: #2c3e50;
            font-weight: 500;
            padding-right: 50px;
        }
        @keyframes scroll {
            0% { transform: translateX(0); }
            100% { transform: translateX(-100%); }
        }

        /* Phrase button styles for both themes */
        .phrase-btn {
            padding: 8px 16px;
            background-color: #e8f4f8;
            border: 1px solid #3498db;
            border-radius: 5px;
            color: #2c3e50;
            font-size: 14px;
            cursor: pointer;
            margin: 5px;
            transition: all 0.3s ease;
        }
        .phrase-btn:hover {
            background-color: #d1ecf1;
            border-color: #2980b9;
        }
        .try-phrase-btn {
            background-color: #f8f9fa;
            border-color: #6c757d;
        }
        .try-phrase-btn:hover {
            background-color: #e9ecef;
        }

        .info-banner {
            background-color: #fff3cd;
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-size: 14px;
            color: #856404;
        }

        /* Modern Theme Styles */
        body.modern {
            padding: 20px;
            background-color: #1a1a1a;
            color: #f1f5f9;
        }
        .modern .container {
            background-color: #2c2c2c;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        .modern h1 {
            color: #60a5fa;
        }
        .modern p {
            color: #cbd5e1;
        }
        .modern p:last-of-type {
            color: #94a3b8;
        }
        .modern .info-banner {
            background-color: #fff3cd !important;
            color: #111827 !important;
            border: 1px solid #fcd34d !important;
        }
        .modern .info-banner strong {
            color: #111827 !important;
        }
        .modern .scrolling-wrapper {
            background-color: #374151;
            border-left-color: #60a5fa;
        }
        .modern .scrolling-text {
            color: #e2e8f0;
        }
        .modern .controls {
            margin: 30px 0;
        }
        .modern .controls label {
            color: #e2e8f0;
        }
        .modern select, .modern input {
            background-color: #374151;
            border-color: #60a5fa;
            color: #f1f5f9;
        }
        .modern #recordBtn {
            background-color: #e74c3c;
            color: white;
        }
        .modern #recordBtn.recording {
            background-color: #c0392b;
        }
        .modern .dropzone {
            border-color: #60a5fa;
            background-color: #374151;
        }
        .modern .dropzone:hover {
            background-color: #4b5563;
            border-color: #60a5fa;
        }
        .modern .dropzone h3 {
            color: #60a5fa;
        }
        .modern .dropzone p {
            color: #cbd5e1;
        }
        .modern .result-box {
            border-color: #4b5563;
            background-color: #1f2937;
            color: #e2e8f0;
        }
        .modern .result-box > h3 {
            color: #f8fafc;
        }
        .modern #smallResult,
        .modern #mediumResult,
        .modern #largeResult,
        .modern #comparisonResult,
        .modern #topMatchesSection {
            color: #111827;
        }
        .modern #result p,
        .modern #result strong,
        .modern #result span,
        .modern #result .translation,
        .modern #result .transcription {
            color: #111827 !important;
        }
        .modern #smallResult h4,
        .modern #mediumResult h4,
        .modern #largeResult h4,
        .modern #comparisonResult h4,
        .modern #topMatchesSection h4 {
            color: inherit;
        }
        .modern #topMatchesSection strong {
            color: inherit;
        }
        .modern .transcription {
            color: #475569;
        }
        .modern .translation {
            color: #15803d;
        }
        .modern .status {
            color: #cbd5e1;
        }
        .modern #silenceValue {
            color: #fbbf24;
        }
    </style>
</head>
<body class="modern">
    <div class="container">
        <button id="themeToggle" class="theme-toggle" aria-pressed="true">Light Mode</button>
        <h1>AfricanVoice üéôÔ∏è By Resulam</h1>
        <p>Parlez en fran√ßais, anglais ou espagnol pour obtenir la traduction en Nufi.</p>
        <p style="font-size: 14px; color: #7f8c8d;">Speak in French, English, or Spanish to get the Nufi translation.</p>
        <div class="info-banner">
            <strong>üìù Tips:</strong> Click record, and allow microphone access when prompted.
        </div>


        <div class="scrolling-wrapper" id="scrollingWrapper">
            <!-- Content populated by JavaScript -->
        </div>
        
        <!-- Debug: App Mode: {{ app_mode }} -->
        
        <div class="controls">
            <div style="margin-bottom: 15px;">
                <label for="languageSelect" style="font-weight: bold; margin-right: 10px;">üåç See the Transcription in:</label>
                <select id="languageSelect" style="padding: 8px 15px; font-size: 14px; border-radius: 5px; border: 2px solid #3498db; cursor: pointer;">
                    <option value="auto">Auto-detect</option>
                    <option value="fr" selected>French (Fran√ßais)</option>
                    <option value="en">English</option>
                    <option value="es">Spanish (Espa√±ol)</option>
                    <option value="de">German (Deutsch)</option>
                    <option value="it">Italian (Italiano)</option>
                    <option value="pt">Portuguese (Portugu√™s)</option>
                </select>
            </div>
            <div style="margin-bottom: 15px;">
                <label for="silenceDuration" style="font-weight: bold; margin-right: 10px;">‚è±Ô∏è Silence Duration (seconds):</label>
                <input type="range" id="silenceDuration" min="1" max="10" value="3" step="0.5" style="cursor: pointer;">
                <span id="silenceValue" style="margin-left: 10px; font-weight: bold; color: #e67e22;">3.0s</span>
            </div>
            <!-- Microphone sensitivity control removed from UI (kept as configuration only) -->
            <button id="recordBtn">üé§ Start Recording</button>
        </div>
        
        <div class="dropzone" id="dropzone">
            <h3 style="color: #3498db; margin: 10px 0;">üìÅ Drag & Drop Audio File Here</h3>
            <p style="color: #7f8c8d; margin: 10px 0;">or click to browse</p>
            <p style="font-size: 12px; color: #95a5a6;">Supports MP3, WAV, WebM, M4A and other audio formats</p>
            <input type="file" id="audioUpload" accept="audio/*,.mp3,.wav,.webm,.m4a" style="display: none;">
        </div>

        <div id="status" class="status">Ready</div>

        <div id="result" class="result-box">
            {% if app_mode != 'production' %}
            <h3>üéØ Three-Way Model Comparison:</h3>
            
            <!-- Whisper Small Result -->
            <div id="smallResult" style="background: #fff3cd; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ffc107;">
                <h4 style="margin: 0 0 10px 0; color: #856404;">üü° Whisper Small (~466MB - Fast)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="smallText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="smallMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="smallTranslation" class="translation"></span></p>
            </div>
            
            <!-- Whisper Medium Result -->
            <div id="mediumResult" style="background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #3498db;">
                <h4 style="margin: 0 0 10px 0; color: #2980b9;">üîµ Whisper Medium (~1.5GB - Balanced)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="mediumText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="mediumMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="mediumTranslation" class="translation"></span></p>
            </div>
            {% endif %}
            
            {% if app_mode == 'production' %}
            <h3>üéØ Whisper Large-v3 Result</h3>
            {% endif %}
            
            <!-- Whisper Large-v3 Result -->
            <div id="largeResult" style="background: #e8f4e8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #27ae60;">
                <h4 style="margin: 0 0 10px 0; color: #229954;">üü¢ Whisper Large-v3 (~2.87GB - Most Accurate)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="largeText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="largeMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="largeTranslation" class="translation"></span></p>
            </div>
            
            {% if app_mode == 'production' %}
            <!-- Top 5 Semantic Matches (Production Mode) -->
            <div id="topMatchesSection" style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #6c757d;">
                <h4 style="margin: 0 0 10px 0; color: #495057;">üéØ Top 5 Semantic Matches</h4>
                <div id="topMatchesContainer"></div>
            </div>
            {% endif %}
            
            {% if app_mode != 'production' %}
            <!-- Comparison -->
            <div id="comparisonResult" style="background: #d1ecf1; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #17a2b8;">
                <h4 style="margin: 0 0 10px 0; color: #0c5460;">‚öñÔ∏è Comparison</h4>
                <p id="comparisonText" style="margin: 5px 0;"></p>
            </div>
            {% endif %}
            
            <audio id="audioPlayer" controls style="width: 100%; margin-top: 10px; display: none;"></audio>
            
            <div id="noMatch" style="display:none; color: #e67e22;">
                No close match found in dictionary for either model.
            </div>
        </div>
    </div>

    <script>
        // Theme toggle functionality
        document.addEventListener('DOMContentLoaded', function() {
                const themeToggle = document.getElementById('themeToggle');
                const body = document.body;

                // Initialize button state on load
                function updateThemeToggle() {
                    const isDark = body.classList.contains('modern');
                    themeToggle.textContent = isDark ? 'Light Mode' : 'Dark Mode';
                    themeToggle.setAttribute('aria-pressed', isDark ? 'true' : 'false');
                    // apply light variant class when showing 'Dark Mode' (meaning currently light)
                    if (isDark) themeToggle.classList.remove('light');
                    else themeToggle.classList.add('light');
                }

                themeToggle.addEventListener('click', function() {
                    if (body.classList.contains('modern')) {
                        body.classList.remove('modern');
                    } else {
                        body.classList.add('modern');
                    }
                    updateThemeToggle();
                });

                // Run once to set initial label/appearance
                updateThemeToggle();
        });

        function setPhrase(phrase) {
            alert('Phrase selected: ' + phrase + '\n\nPlease speak this phrase into the microphone when recording.');
        }

        // --- Configuration for Scrolling Text ---
        const examplePhrases = [
            "Salut", 
            "Hello", 
            "Buenos dias", 
            "Je m'appelle...", 
            "My name is ...", 
            "Thank you",
            "Gamsahamnida", 
            "Merci", 
            "Je suis heureux", 
            "I am happy", 
            "Je suis fatigu√©", 
            "J'ai faim", 
            "Tengo Hambre",
            "Comment √ßa va ?", 
            "L'assiette", 
            "La chaise",
        ];

        function initScrollingText() {
            const wrapper = document.getElementById('scrollingWrapper');
            if (!wrapper) return;
            
            const textContent = "Try saying: " + examplePhrases.join(" &nbsp; ‚Ä¢ &nbsp; ");
            
            // Create two identical divs for the infinite loop effect
            for (let i = 0; i < 2; i++) {
                const div = document.createElement('div');
                div.className = 'scrolling-text';
                div.innerHTML = textContent;
                wrapper.appendChild(div);
            }
        }
        
        // Initialize immediately
        initScrollingText();

        const recordBtn = document.getElementById('recordBtn');
        const statusDiv = document.getElementById('status');
        const countdownDiv = document.createElement('div');
        countdownDiv.id = 'countdown';
        countdownDiv.style.cssText = 'font-weight: bold; color: #e67e22; min-height: 20px; margin-top: 5px;';
        statusDiv.parentNode.insertBefore(countdownDiv, statusDiv.nextSibling);

        const resultDiv = document.getElementById('result');
        const transcriptionText = document.getElementById('transcriptionText');
        const matchedFrench = document.getElementById('matchedFrench');
        const translationText = document.getElementById('translationText');
        const audioPlayer = document.getElementById('audioPlayer');
        const matchResult = document.getElementById('matchResult');
        const noMatch = document.getElementById('noMatch');

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        
        // Silence detection variables
        let audioContext;
        let analyser;
        let microphone;
        let silenceTimer;
        let initialSilenceTimer;
        let hasSpoken = false;
        let shouldSend = true;
        // Default silence threshold (20% = quiet/ignore most ambient noise)
        let SILENCE_THRESHOLD = 0.20; // Default - now configured to 20% by default
        let SILENCE_DURATION = 3000; // Default 3 seconds, will be updated from slider
        
        // Noise filtering variables
        let speechStartTime = 0;
        const MIN_SPEECH_DURATION = 300; // ms of continuous sound required to count as speech
        
        // Continuous listening variables
        let processingQueue = [];
        let isProcessing = false;
        let continuousMode = false;
        let isResetting = false;
        
        // Countdown variables
        let lastSpeechTime = 0;
        let countdownInterval;

        // Setup silence duration slider
        const silenceSlider = document.getElementById('silenceDuration');
        const silenceValue = document.getElementById('silenceValue');
        silenceSlider.addEventListener('input', () => {
            const value = parseFloat(silenceSlider.value);
            SILENCE_DURATION = value * 1000; // Convert to milliseconds
            silenceValue.textContent = value.toFixed(1) + 's';
        });
        // Initialize
        silenceSlider.dispatchEvent(new Event('input'));

        // Sensitivity control: optional ‚Äî take action only if control exists in the DOM.
        const thresholdSlider = document.getElementById('silenceThreshold');
        const thresholdValue = document.getElementById('thresholdValue');
        if (thresholdSlider && thresholdValue) {
            thresholdSlider.addEventListener('input', () => {
                const val = parseInt(thresholdSlider.value);
                // Map 1-20 to 0.01 - 0.20
                SILENCE_THRESHOLD = val / 100;

                let label = 'Normal';
                if (val < 2) label = 'Very Sensitive';
                else if (val < 4) label = 'Sensitive';
                else if (val < 8) label = 'Normal';
                else if (val < 15) label = 'Low Sensitivity';
                else label = 'Very Low';

                thresholdValue.textContent = `${label} (${val}%)`;
            });
            // Initialize
            thresholdSlider.dispatchEvent(new Event('input'));
        } else {
            // No visible control ‚Äî keep default value and (if present) set label text
            SILENCE_THRESHOLD = 0.20; // 20%
            if (thresholdValue) thresholdValue.textContent = `Very Low (20%)`;
        }

        recordBtn.addEventListener('click', toggleRecording);
        
        // File upload and drag-drop handlers
        const audioUpload = document.getElementById('audioUpload');
        const dropzone = document.getElementById('dropzone');
        
        audioUpload.addEventListener('change', handleFileUpload);
        
        // Click to browse
        dropzone.addEventListener('click', () => {
            audioUpload.click();
        });
        
        // Drag and drop events
        dropzone.addEventListener('dragover', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.add('dragover');
        });
        
        dropzone.addEventListener('dragleave', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.remove('dragover');
        });
        
        dropzone.addEventListener('drop', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                const file = files[0];
                // Check if it's an audio file
                if (file.type.startsWith('audio/') || file.name.match(/\.(mp3|wav|webm|m4a|ogg|flac|aac)$/i)) {
                    processUploadedFile(file);
                } else {
                    statusDiv.textContent = 'Error: Please drop an audio file';
                }
            }
        });
        
        async function handleFileUpload(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            processUploadedFile(file);
            
            // Reset file input
            event.target.value = '';
        }
        
        async function processUploadedFile(file) {
            statusDiv.textContent = 'Processing uploaded file: ' + file.name;
            resultDiv.style.display = 'none';
            
            const formData = new FormData();
            formData.append('audio', file);
            
            // Add selected language
            const language = document.getElementById('languageSelect').value;
            formData.append('language', language);
            
            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (response.ok) {
                    displayResult(data);
                    statusDiv.textContent = 'Done';
                } else {
                    statusDiv.textContent = 'Error: ' + (data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Error processing file:', err);
                statusDiv.textContent = 'Network error occurred.';
            }
        }

        async function toggleRecording() {
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    
                    mediaRecorder.ondataavailable = (event) => {
                        if (isResetting) return;
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        // In continuous mode, don't stop on onstop event
                        if (!continuousMode && shouldSend) {
                            sendAudio();
                        } else if (!continuousMode) {
                            statusDiv.textContent = 'Recording cancelled (timeout).';
                        }
                        if (!continuousMode) {
                            cleanupAudioContext();
                        }
                    };

                    audioChunks = [];
                    mediaRecorder.start(200); // Capture chunks every 200ms to ensure data is available
                    isRecording = true;
                    continuousMode = true;
                    shouldSend = true;
                    hasSpoken = false;
                    processingQueue = [];
                    isProcessing = false;
                    
                    recordBtn.textContent = '‚èπÔ∏è Stop Listening';
                    recordBtn.classList.add('recording');
                    statusDiv.textContent = 'Listening... (Speak now)';
                    resultDiv.style.display = 'none';
                    
                    // Setup silence detection
                    setupSilenceDetection(stream);
                    
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    statusDiv.textContent = 'Error: Could not access microphone. Please allow permissions.';
                }
            } else {
                // User manually stopped - exit continuous mode
                continuousMode = false;
                stopRecording(true);
            }
        }
        
        function stopRecording(send) {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                shouldSend = send;
                mediaRecorder.stop();
                isRecording = false;
                recordBtn.textContent = 'üé§ Start Recording';
                recordBtn.classList.remove('recording');
                if (send) {
                    statusDiv.textContent = 'Processing...';
                }
            }
        }
        
        function setupSilenceDetection(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);
            const scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);

            analyser.fftSize = 2048;
            microphone.connect(analyser);
            analyser.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);

            // Initial silence timeout (reset if no speech within 5s)
            initialSilenceTimer = setTimeout(() => {
                if (!hasSpoken) {
                    console.log("Initial silence timeout - no speech detected");
                    if (continuousMode) {
                        // In continuous mode, just reset and keep listening
                        audioChunks = [];
                        hasSpoken = false;
                        statusDiv.textContent = 'Listening... (no speech detected, continuing)';
                    } else {
                        stopRecording(false); // Stop and DO NOT send
                    }
                }
            }, SILENCE_DURATION);

            scriptProcessor.onaudioprocess = function() {
                if (!isRecording) return;
                
                const array = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(array);
                
                // Calculate voice band volume (approx 300Hz - 3400Hz)
                // This filters out low frequency noise (table hits) and high frequency hiss
                const sampleRate = audioContext.sampleRate;
                const binSize = sampleRate / analyser.fftSize;
                const startBin = Math.floor(300 / binSize);
                const endBin = Math.floor(3400 / binSize);
                
                let values = 0;
                let binsCounted = 0;
                
                for (let i = startBin; i < endBin && i < array.length; i++) {
                    values += array[i];
                    binsCounted++;
                }
                
                const average = binsCounted > 0 ? values / binsCounted : 0;
                const volume = average / 255; // Normalize to 0-1

                if (volume > SILENCE_THRESHOLD) {
                    // Potential speech detected
                    if (speechStartTime === 0) {
                        speechStartTime = Date.now();
                    }
                    
                    const duration = Date.now() - speechStartTime;
                    
                    // Only trigger if sound persists longer than MIN_SPEECH_DURATION (filters out claps/noise)
                    // OR if we are already in a speech session (to catch short words after the initial trigger)
                    if (duration > MIN_SPEECH_DURATION || hasSpoken) {
                        // Speech detected
                        if (!hasSpoken) {
                            console.log("Speech detected (start)");
                            hasSpoken = true;
                            startCountdownDisplay();
                            
                            // In continuous mode, trim leading silence to avoid sending huge files
                            // Keep last 5 chunks (approx 1 second) for context
                            if (continuousMode && audioChunks.length > 5) {
                                console.log(`Trimming silence. Keeping last 5 of ${audioChunks.length} chunks`);
                                // Preserve the header (chunk 0) and keep the last 5 chunks
                                const header = audioChunks[0];
                                const recent = audioChunks.slice(-5);
                                audioChunks = [header, ...recent];
                            }

                            clearTimeout(initialSilenceTimer);
                            statusDiv.textContent = continuousMode ? 'Listening... (Speech detected)' : 'Recording... (Speech detected)';
                        }
                        
                        // Reset post-speech silence timer
                        lastSpeechTime = Date.now();
                        clearTimeout(silenceTimer);
                        silenceTimer = setTimeout(() => {
                            console.log("Post-speech silence timeout - processing segment");
                            if (continuousMode) {
                                // Queue the segment and continue listening
                                queueAudioSegment();
                            } else {
                                // Original behavior: stop and send
                                stopRecording(true);
                            }
                        }, SILENCE_DURATION);
                    } else if (!hasSpoken) {
                        // Visual feedback for noise that is being ignored (too short)
                        statusDiv.textContent = 'Listening... (Ignoring noise)';
                    }
                } else {
                    // Silence detected - reset speech start time
                    speechStartTime = 0;
                    if (!hasSpoken && continuousMode && statusDiv.textContent.includes('Ignoring noise')) {
                        statusDiv.textContent = 'Listening...';
                    }
                }
            };
        }
        
        function cleanupAudioContext() {
            if (audioContext && !continuousMode) {
                audioContext.close();
                audioContext = null;
            }
            clearTimeout(silenceTimer);
            clearTimeout(initialSilenceTimer);
            clearInterval(countdownInterval);
            if (countdownDiv) countdownDiv.textContent = '';
        }

        function startCountdownDisplay() {
            clearInterval(countdownInterval);
            countdownInterval = setInterval(() => {
                if (!isRecording || !hasSpoken) {
                    countdownDiv.textContent = '';
                    return;
                }
                
                const elapsed = Date.now() - lastSpeechTime;
                const remaining = Math.max(0, SILENCE_DURATION - elapsed);
                const seconds = (remaining / 1000).toFixed(1);
                
                if (remaining <= 0) {
                    countdownDiv.textContent = 'Processing...';
                } else {
                    countdownDiv.textContent = `Processing in ${seconds}s`;
                }
            }, 100);
        }

        function queueAudioSegment() {
            if (audioChunks.length === 0) {
                console.log('No audio to queue');
                hasSpoken = false;
                return;
            }
            
            // Create a blob from current chunks and add to queue
            const segmentBlob = new Blob(audioChunks, { type: 'audio/webm' });
            if (segmentBlob.size < 1000) {
                console.log('Segment too small, skipping');
                audioChunks = [];
                hasSpoken = false;
                return;
            }
            
            processingQueue.push(segmentBlob);
            console.log(`Queued segment. Queue length: ${processingQueue.length}. isProcessing: ${isProcessing}`);
            
            // Clear chunks for next segment
            audioChunks = [];
            hasSpoken = false;
            
            // Restart recorder to ensure valid WebM header for next segment
            if (isRecording && continuousMode) {
                isResetting = true;
                mediaRecorder.stop();
                setTimeout(() => {
                    if (isRecording && continuousMode) {
                        mediaRecorder.start(200);
                        isResetting = false;
                        console.log("Recorder restarted for next segment");
                    }
                }, 200);
            }
            
            // Update status
            if (isProcessing) {
                statusDiv.textContent = `Listening... (${processingQueue.length} in queue)`;
            } else {
                statusDiv.textContent = 'Listening... (processing)';
            }
            
            // Start processing if not already processing
            if (!isProcessing) {
                console.log("Starting processQueue from queueAudioSegment");
                processQueue();
            }
        }
        
        async function processQueue() {
            console.log(`processQueue called. Queue length: ${processingQueue.length}`);
            if (processingQueue.length === 0) {
                isProcessing = false;
                if (continuousMode) {
                    statusDiv.textContent = 'Listening...';
                }
                return;
            }
            
            isProcessing = true;
            const segmentBlob = processingQueue.shift();
            
            const formData = new FormData();
            formData.append('audio', segmentBlob, 'segment.webm');
            const language = document.getElementById('languageSelect').value;
            formData.append('language', language);
            
            try {
                const queueInfo = processingQueue.length > 0 ? ` (${processingQueue.length} in queue)` : '';
                statusDiv.textContent = `Processing...${queueInfo}`;
                
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });
                
                const data = await response.json();
                
                if (response.ok) {
                    displayResult(data);
                    if (continuousMode) {
                        statusDiv.textContent = processingQueue.length > 0 ? 
                            `Listening... (${processingQueue.length} in queue)` : 'Listening...';
                    } else {
                        statusDiv.textContent = 'Done';
                    }
                } else {
                    statusDiv.textContent = 'Error: ' + (data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Error processing segment:', err);
                statusDiv.textContent = 'Network error occurred.';
            }
            
            // Process next item in queue
            setTimeout(() => processQueue(), 100);
        }

        async function sendAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');
            
            // Add selected language
            const language = document.getElementById('languageSelect').value;
            formData.append('language', language);

            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (response.ok) {
                    displayResult(data);
                    statusDiv.textContent = 'Done';
                } else {
                    statusDiv.textContent = 'Error: ' + (data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Error sending audio:', err);
                statusDiv.textContent = 'Network error occurred.';
            }
        }

        // Audio playback functions
        function playWordAudio(audioUrl) {
            if (!audioUrl) {
                console.log('No audio available for this word');
                return;
            }
            const audio = new Audio(audioUrl);
            audio.play().catch(err => {
                console.error('Error playing audio:', err);
            });
        }
        
        function playSentenceAudio(audioUrl) {
            if (!audioUrl) {
                console.log('No audio available for this sentence');
                return;
            }
            const audio = new Audio(audioUrl);
            audio.play().catch(err => {
                console.error('Error playing sentence audio:', err);
            });
        }
        
        function renderNufiWithAudio(match, containerElement) {
            containerElement.innerHTML = ''; // Clear
            
            if (!match) {
                containerElement.textContent = 'N/A';
                return;
            }
            
            const nufiText = match.Nufi || '';
            const wordAudio = match.word_audio || [];
            const sentenceAudioUrl = match.sentence_audio_url;
            
            // Create clickable words
            if (wordAudio.length > 0) {
                wordAudio.forEach((wordObj, index) => {
                    const wordSpan = document.createElement('span');
                    wordSpan.textContent = wordObj.word;
                    wordSpan.className = 'nufi-word';
                    
                    if (wordObj.audio_url) {
                        wordSpan.style.cursor = 'pointer';
                        wordSpan.style.color = '#3498db';
                        wordSpan.style.textDecoration = 'underline';
                        wordSpan.style.textDecorationStyle = 'dotted';
                        wordSpan.title = 'Click to hear pronunciation';
                        wordSpan.onclick = () => playWordAudio(wordObj.audio_url);
                    }
                    
                    containerElement.appendChild(wordSpan);
                    
                    // Add space between words (except last)
                    if (index < wordAudio.length - 1) {
                        containerElement.appendChild(document.createTextNode(' '));
                    }
                });
            } else {
                containerElement.textContent = nufiText;
            }
            
            // Add sentence play button
            if (sentenceAudioUrl) {
                const playBtn = document.createElement('button');
                playBtn.innerHTML = 'üîä Play Full Sentence';
                playBtn.style.marginLeft = '10px';
                playBtn.style.padding = '5px 10px';
                playBtn.style.fontSize = '12px';
                playBtn.style.cursor = 'pointer';
                playBtn.style.backgroundColor = '#27ae60';
                playBtn.style.color = 'white';
                playBtn.style.border = 'none';
                playBtn.style.borderRadius = '4px';
                playBtn.onclick = () => playSentenceAudio(sentenceAudioUrl);
                containerElement.appendChild(document.createTextNode(' '));
                containerElement.appendChild(playBtn);
            }
        }

        function displayResult(data) {
            resultDiv.style.display = 'block';
            
            // Auto-scroll to show the result
            setTimeout(() => {
                resultDiv.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }, 100);
            
            // Whisper Small results (present only in development UI)
            const smallText = document.getElementById('smallText');
            const smallMatch = document.getElementById('smallMatch');
            const smallTranslation = document.getElementById('smallTranslation');
            if (smallText && smallMatch && smallTranslation) {
                smallText.textContent = data.transcription_small || 'N/A';
                if (data.match_small) {
                    smallMatch.textContent = data.match_small.French || 'N/A';
                    renderNufiWithAudio(data.match_small, smallTranslation);
                    // Auto-play removed for Small model as per user request
                } else {
                    smallMatch.textContent = 'No match';
                    smallTranslation.textContent = 'N/A';
                }
            }
            
            // Whisper Medium results (present only in development UI)
            const mediumText = document.getElementById('mediumText');
            const mediumMatch = document.getElementById('mediumMatch');
            const mediumTranslation = document.getElementById('mediumTranslation');
            if (mediumText && mediumMatch && mediumTranslation) {
                mediumText.textContent = data.transcription_medium || 'N/A';
                if (data.match_medium) {
                    mediumMatch.textContent = data.match_medium.French || 'N/A';
                    renderNufiWithAudio(data.match_medium, mediumTranslation);
                    // Auto-play removed for Medium model as per user request
                } else {
                    mediumMatch.textContent = 'No match';
                    mediumTranslation.textContent = 'N/A';
                }
            }
            
            // Whisper Large-v3 results
            const largeText = document.getElementById('largeText');
            const largeMatch = document.getElementById('largeMatch');
            const largeTranslation = document.getElementById('largeTranslation');
            
            largeText.textContent = data.transcription_large || 'N/A';
            
            // Use the match provided by the backend (which is now the best hybrid match in both modes)
            const bestMatch = data.match_large;
            
            if (bestMatch) {
                largeMatch.textContent = bestMatch.French || 'N/A';
                renderNufiWithAudio(bestMatch, largeTranslation);
                
                // Auto-play logic: ONLY play for Large model match
                // Set threshold to 90% to catch excellent semantic matches like "Je suis √† l'aise" (90.5%)
                const isGoodMatch = bestMatch.match_score >= 90 && bestMatch.sentence_audio_url &&
                                   (bestMatch.match_type === 'exact' || bestMatch.match_type === 'multi-word' || bestMatch.match_type === 'semantic');
                
                if (isGoodMatch) {
                    setTimeout(() => playSentenceAudio(bestMatch.sentence_audio_url), 300);
                }
            } else {
                largeMatch.textContent = 'No match';
                largeTranslation.textContent = 'N/A';
            }
            
            // Display top 5 semantic matches in production mode
            const topMatchesSection = document.getElementById('topMatchesSection');
            const topMatchesContainer = document.getElementById('topMatchesContainer');
            if (topMatchesSection && topMatchesContainer && data.top_matches) {
                topMatchesContainer.innerHTML = ''; // Clear previous results
                
                if (data.top_matches.length > 0) {
                    data.top_matches.forEach((match, index) => {
                        const matchDiv = document.createElement('div');
                        matchDiv.style.cssText = 'background: white; padding: 10px; margin: 5px 0; border-radius: 5px; border: 1px solid #dee2e6;';
                        
                        const rank = index + 1;
                        const score = match.match_score ? match.match_score.toFixed(1) : 'N/A';
                        
                        matchDiv.innerHTML = `
                            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px;">
                                <strong style="color: #495057;">#${rank} Match (${score}% similarity)</strong>
                                <span style="font-size: 0.8em; color: #6c757d;">${match.match_type || 'semantic'}</span>
                            </div>
                            <div style="margin: 5px 0;"><strong>French:</strong> ${match.French || 'N/A'}</div>
                            <div style="margin: 5px 0;"><strong>Nufi:</strong> <span class="translation-${index}"></span></div>
                        `;
                        
                        topMatchesContainer.appendChild(matchDiv);
                        
                        // Render Nufi with audio for this match
                        const translationElement = matchDiv.querySelector(`.translation-${index}`);
                        if (translationElement) {
                            renderNufiWithAudio(match, translationElement);
                        }
                    });
                    
                    topMatchesSection.style.display = 'block';
                } else {
                    topMatchesSection.style.display = 'none';
                }
            }
            
            // Comparison section (development UI only)
            const comparisonText = document.getElementById('comparisonText');
            const small = data.transcription_small || '';
            const medium = data.transcription_medium || '';
            const large = data.transcription_large || '';
            if (comparisonText) {
                if (small.toLowerCase() === medium.toLowerCase() && medium.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚úÖ <strong>All three models agree!</strong><br>Transcription: "' + small + '"';
                    comparisonText.style.color = '#155724';
                } else if (small.toLowerCase() === medium.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Small and Medium agree</strong> (Large-v3 differs)<br>' +
                        'Small & Medium: "' + small + '"<br>' +
                        'Large-v3: "' + large + '"';
                    comparisonText.style.color = '#0c5460';
                } else if (small.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Small and Large-v3 agree</strong> (Medium differs)<br>' +
                        'Small & Large: "' + small + '"<br>' +
                        'Medium: "' + medium + '"';
                    comparisonText.style.color = '#0c5460';
                } else if (medium.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Medium and Large-v3 agree</strong> (Small differs)<br>' +
                        'Small: "' + small + '"<br>' +
                        'Medium & Large: "' + medium + '"';
                    comparisonText.style.color = '#0c5460';
                } else {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Different results</strong><br>' +
                        'Small: "' + small + '"<br>' +
                        'Medium: "' + medium + '"<br>' +
                        'Large-v3: "' + large + '"';
                    comparisonText.style.color = '#856404';
                }
            }
            
            // Show/hide no match message
            const hasAnyMatch = data.match_small || data.match_medium || data.match_large || 
                               (data.top_matches && data.top_matches.length > 0);
            if (!hasAnyMatch) {
                document.getElementById('noMatch').style.display = 'block';
            } else {
                document.getElementById('noMatch').style.display = 'none';
            }
        }
    </script>
</body>
</html>
