<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AfricanVoice - Voice Translator</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max_width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        h1 { color: #2c3e50; }
        .controls { margin: 30px 0; }
        button {
            padding: 15px 30px;
            font-size: 18px;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
        }
        #recordBtn {
            background-color: #e74c3c;
            color: white;
        }
        #recordBtn.recording {
            background-color: #c0392b;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        .dropzone {
            border: 3px dashed #3498db;
            border-radius: 15px;
            padding: 40px;
            margin: 20px 0;
            text-align: center;
            background-color: #f8f9fa;
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .dropzone:hover {
            background-color: #e3f2fd;
            border-color: #2980b9;
        }
        .dropzone.dragover {
            background-color: #d1ecf1;
            border-color: #0c5460;
            transform: scale(1.02);
        }
        .result-box {
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 10px;
            display: none;
        }
        .transcription {
            font-style: italic;
            color: #7f8c8d;
            margin-bottom: 15px;
        }
        .translation {
            font-size: 24px;
            font-weight: bold;
            color: #27ae60;
            margin-bottom: 15px;
        }
        .status {
            margin-top: 10px;
            color: #666;
        }
        /* Scrolling Text Styles */
        .scrolling-wrapper {
            overflow: hidden;
            white-space: nowrap;
            background-color: #e8f4f8;
            padding: 10px 0;
            margin: 15px 0;
            border-radius: 5px;
            border-left: 5px solid #3498db;
            display: flex;
        }
        .scrolling-text {
            animation: scroll 40s linear infinite;
            font-size: 16px;
            color: #2c3e50;
            font-weight: 500;
            padding-right: 50px;
        }
        @keyframes scroll {
            0% { transform: translateX(0); }
            100% { transform: translateX(-100%); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AfricanVoice üéôÔ∏è By Resulam</h1>
        <p>Parlez en fran√ßais, anglais ou espagnol pour obtenir la traduction en Nufi.</p>
        <p style="font-size: 14px; color: #7f8c8d;">Speak in French, English, or Spanish to get the Nufi translation.</p>
        <div style="background-color: #fff3cd; padding: 10px; margin: 10px 0; border-radius: 5px; font-size: 14px;">
            <strong>üìù Tips:</strong> Click record, wait 1 second, then speak clearly for 2-3 seconds. Allow microphone access when prompted.
        </div>


        <div class="scrolling-wrapper" id="scrollingWrapper">
            <!-- Content populated by JavaScript -->
        </div>
        
        <!-- Debug: App Mode: {{ app_mode }} -->
        
        <div class="controls">
            <div style="margin-bottom: 15px;">
                <label for="languageSelect" style="font-weight: bold; margin-right: 10px;">üåç See the Transcription in:</label>
                <select id="languageSelect" style="padding: 8px 15px; font-size: 14px; border-radius: 5px; border: 2px solid #3498db; cursor: pointer;">
                    <option value="auto">Auto-detect</option>
                    <option value="fr" selected>French (Fran√ßais)</option>
                    <option value="en">English</option>
                    <option value="es">Spanish (Espa√±ol)</option>
                    <option value="de">German (Deutsch)</option>
                    <option value="it">Italian (Italiano)</option>
                    <option value="pt">Portuguese (Portugu√™s)</option>
                </select>
            </div>
            <button id="recordBtn">üé§ Start Recording</button>
        </div>
        
        <div class="dropzone" id="dropzone">
            <h3 style="color: #3498db; margin: 10px 0;">üìÅ Drag & Drop Audio File Here</h3>
            <p style="color: #7f8c8d; margin: 10px 0;">or click to browse</p>
            <p style="font-size: 12px; color: #95a5a6;">Supports MP3, WAV, WebM, M4A and other audio formats</p>
            <input type="file" id="audioUpload" accept="audio/*,.mp3,.wav,.webm,.m4a" style="display: none;">
        </div>

        <div id="status" class="status">Ready</div>

        <div id="result" class="result-box">
            {% if app_mode != 'production' %}
            <h3>üéØ Three-Way Model Comparison:</h3>
            
            <!-- Whisper Small Result -->
            <div id="smallResult" style="background: #fff3cd; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #ffc107;">
                <h4 style="margin: 0 0 10px 0; color: #856404;">üü° Whisper Small (~466MB - Fast)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="smallText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="smallMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="smallTranslation" class="translation"></span></p>
            </div>
            
            <!-- Whisper Medium Result -->
            <div id="mediumResult" style="background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #3498db;">
                <h4 style="margin: 0 0 10px 0; color: #2980b9;">üîµ Whisper Medium (~1.5GB - Balanced)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="mediumText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="mediumMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="mediumTranslation" class="translation"></span></p>
            </div>
            {% endif %}
            
            {% if app_mode == 'production' %}
            <h3>üéØ Whisper Large-v3 Result</h3>
            {% endif %}
            
            <!-- Whisper Large-v3 Result -->
            <div style="background: #e8f4e8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #27ae60;">
                <h4 style="margin: 0 0 10px 0; color: #229954;">üü¢ Whisper Large-v3 (~2.87GB - Most Accurate)</h4>
                <p style="margin: 5px 0;"><strong>Transcription:</strong> <span id="largeText" class="transcription"></span></p>
                <p style="margin: 5px 0;"><strong>Matched French:</strong> <span id="largeMatch" style="font-weight: bold; color: #2c3e50;"></span></p>
                <p style="margin: 5px 0;"><strong>Nufi Translation:</strong> <span id="largeTranslation" class="translation"></span></p>
            </div>
            
            {% if app_mode == 'production' %}
            <!-- Top 5 Semantic Matches (Production Mode) -->
            <div id="topMatchesSection" style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #6c757d;">
                <h4 style="margin: 0 0 10px 0; color: #495057;">üéØ Top 5 Semantic Matches</h4>
                <div id="topMatchesContainer"></div>
            </div>
            {% endif %}
            
            {% if app_mode != 'production' %}
            <!-- Comparison -->
            <div id="comparisonResult" style="background: #d1ecf1; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #17a2b8;">
                <h4 style="margin: 0 0 10px 0; color: #0c5460;">‚öñÔ∏è Comparison</h4>
                <p id="comparisonText" style="margin: 5px 0;"></p>
            </div>
            {% endif %}
            
            <audio id="audioPlayer" controls style="width: 100%; margin-top: 10px; display: none;"></audio>
            
            <div id="noMatch" style="display:none; color: #e67e22;">
                No close match found in dictionary for either model.
            </div>
        </div>
    </div>

    <script>
        // --- Configuration for Scrolling Text ---
        const examplePhrases = [
            "Salut", 
            "Hello", 
            "Buenos dias", 
            "Je m'appelle...", 
            "My name is ...", 
            "Thank you",
            "Gamsahamnida", 
            "Merci", 
            "Je suis heureux", 
            "I am happy", 
            "Je suis fatigu√©", 
            "J'ai faim", 
            "Tengo Hambre",
            "Comment √ßa va ?", 
            "L'assiette", 
            "La chaise",
        ];

        function initScrollingText() {
            const wrapper = document.getElementById('scrollingWrapper');
            if (!wrapper) return;
            
            const textContent = "Try saying: " + examplePhrases.join(" &nbsp; ‚Ä¢ &nbsp; ");
            
            // Create two identical divs for the infinite loop effect
            for (let i = 0; i < 2; i++) {
                const div = document.createElement('div');
                div.className = 'scrolling-text';
                div.innerHTML = textContent;
                wrapper.appendChild(div);
            }
        }
        
        // Initialize immediately
        initScrollingText();

        const recordBtn = document.getElementById('recordBtn');
        const statusDiv = document.getElementById('status');
        const resultDiv = document.getElementById('result');
        const transcriptionText = document.getElementById('transcriptionText');
        const matchedFrench = document.getElementById('matchedFrench');
        const translationText = document.getElementById('translationText');
        const audioPlayer = document.getElementById('audioPlayer');
        const matchResult = document.getElementById('matchResult');
        const noMatch = document.getElementById('noMatch');

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        
        // Silence detection variables
        let audioContext;
        let analyser;
        let microphone;
        let silenceTimer;
        let initialSilenceTimer;
        let hasSpoken = false;
        let shouldSend = true;
        const SILENCE_THRESHOLD = 0.02; // Adjust based on microphone sensitivity
        const SILENCE_DURATION = 5000; // 5 seconds

        recordBtn.addEventListener('click', toggleRecording);
        
        // File upload and drag-drop handlers
        const audioUpload = document.getElementById('audioUpload');
        const dropzone = document.getElementById('dropzone');
        
        audioUpload.addEventListener('change', handleFileUpload);
        
        // Click to browse
        dropzone.addEventListener('click', () => {
            audioUpload.click();
        });
        
        // Drag and drop events
        dropzone.addEventListener('dragover', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.add('dragover');
        });
        
        dropzone.addEventListener('dragleave', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.remove('dragover');
        });
        
        dropzone.addEventListener('drop', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropzone.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                const file = files[0];
                // Check if it's an audio file
                if (file.type.startsWith('audio/') || file.name.match(/\.(mp3|wav|webm|m4a|ogg|flac|aac)$/i)) {
                    processUploadedFile(file);
                } else {
                    statusDiv.textContent = 'Error: Please drop an audio file';
                }
            }
        });
        
        async function handleFileUpload(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            processUploadedFile(file);
            
            // Reset file input
            event.target.value = '';
        }
        
        async function processUploadedFile(file) {
            statusDiv.textContent = 'Processing uploaded file: ' + file.name;
            resultDiv.style.display = 'none';
            
            const formData = new FormData();
            formData.append('audio', file);
            
            // Add selected language
            const language = document.getElementById('languageSelect').value;
            formData.append('language', language);
            
            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (response.ok) {
                    displayResult(data);
                    statusDiv.textContent = 'Done';
                } else {
                    statusDiv.textContent = 'Error: ' + (data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Error processing file:', err);
                statusDiv.textContent = 'Network error occurred.';
            }
        }

        async function toggleRecording() {
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        if (shouldSend) {
                            sendAudio();
                        } else {
                            statusDiv.textContent = 'Recording cancelled (timeout).';
                        }
                        cleanupAudioContext();
                    };

                    audioChunks = [];
                    mediaRecorder.start();
                    isRecording = true;
                    shouldSend = true; // Default to sending
                    hasSpoken = false;
                    
                    recordBtn.textContent = '‚èπÔ∏è Stop Recording';
                    recordBtn.classList.add('recording');
                    statusDiv.textContent = 'Recording... (Speak now)';
                    resultDiv.style.display = 'none';
                    
                    // Setup silence detection
                    setupSilenceDetection(stream);
                    
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    statusDiv.textContent = 'Error: Could not access microphone. Please allow permissions.';
                }
            } else {
                stopRecording(true); // Manual stop always sends
            }
        }
        
        function stopRecording(send) {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                shouldSend = send;
                mediaRecorder.stop();
                isRecording = false;
                recordBtn.textContent = 'üé§ Start Recording';
                recordBtn.classList.remove('recording');
                if (send) {
                    statusDiv.textContent = 'Processing...';
                }
            }
        }
        
        function setupSilenceDetection(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);
            const scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);

            analyser.fftSize = 2048;
            microphone.connect(analyser);
            analyser.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);

            // Initial silence timeout (reset if no speech within 5s)
            initialSilenceTimer = setTimeout(() => {
                if (!hasSpoken) {
                    console.log("Initial silence timeout - resetting");
                    stopRecording(false); // Stop and DO NOT send
                }
            }, SILENCE_DURATION);

            scriptProcessor.onaudioprocess = function() {
                if (!isRecording) return;
                
                const array = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(array);
                
                // Calculate average volume
                let values = 0;
                const length = array.length;
                for (let i = 0; i < length; i++) {
                    values += array[i];
                }
                const average = values / length;
                const volume = average / 255; // Normalize to 0-1

                if (volume > SILENCE_THRESHOLD) {
                    // Speech detected
                    if (!hasSpoken) {
                        hasSpoken = true;
                        clearTimeout(initialSilenceTimer);
                        statusDiv.textContent = 'Recording... (Speech detected)';
                    }
                    
                    // Reset post-speech silence timer (send after 5s of silence)
                    clearTimeout(silenceTimer);
                    silenceTimer = setTimeout(() => {
                        console.log("Post-speech silence timeout - sending");
                        stopRecording(true); // Stop and SEND
                    }, SILENCE_DURATION);
                }
            };
        }
        
        function cleanupAudioContext() {
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            clearTimeout(silenceTimer);
            clearTimeout(initialSilenceTimer);
        }

        async function sendAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');
            
            // Add selected language
            const language = document.getElementById('languageSelect').value;
            formData.append('language', language);

            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (response.ok) {
                    displayResult(data);
                    statusDiv.textContent = 'Done';
                } else {
                    statusDiv.textContent = 'Error: ' + (data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Error sending audio:', err);
                statusDiv.textContent = 'Network error occurred.';
            }
        }

        // Audio playback functions
        function playWordAudio(audioUrl) {
            if (!audioUrl) {
                console.log('No audio available for this word');
                return;
            }
            const audio = new Audio(audioUrl);
            audio.play().catch(err => {
                console.error('Error playing audio:', err);
            });
        }
        
        function playSentenceAudio(audioUrl) {
            if (!audioUrl) {
                console.log('No audio available for this sentence');
                return;
            }
            const audio = new Audio(audioUrl);
            audio.play().catch(err => {
                console.error('Error playing sentence audio:', err);
            });
        }
        
        function renderNufiWithAudio(match, containerElement) {
            containerElement.innerHTML = ''; // Clear
            
            if (!match) {
                containerElement.textContent = 'N/A';
                return;
            }
            
            const nufiText = match.Nufi || '';
            const wordAudio = match.word_audio || [];
            const sentenceAudioUrl = match.sentence_audio_url;
            
            // Create clickable words
            if (wordAudio.length > 0) {
                wordAudio.forEach((wordObj, index) => {
                    const wordSpan = document.createElement('span');
                    wordSpan.textContent = wordObj.word;
                    wordSpan.className = 'nufi-word';
                    
                    if (wordObj.audio_url) {
                        wordSpan.style.cursor = 'pointer';
                        wordSpan.style.color = '#3498db';
                        wordSpan.style.textDecoration = 'underline';
                        wordSpan.style.textDecorationStyle = 'dotted';
                        wordSpan.title = 'Click to hear pronunciation';
                        wordSpan.onclick = () => playWordAudio(wordObj.audio_url);
                    }
                    
                    containerElement.appendChild(wordSpan);
                    
                    // Add space between words (except last)
                    if (index < wordAudio.length - 1) {
                        containerElement.appendChild(document.createTextNode(' '));
                    }
                });
            } else {
                containerElement.textContent = nufiText;
            }
            
            // Add sentence play button
            if (sentenceAudioUrl) {
                const playBtn = document.createElement('button');
                playBtn.innerHTML = 'üîä Play Full Sentence';
                playBtn.style.marginLeft = '10px';
                playBtn.style.padding = '5px 10px';
                playBtn.style.fontSize = '12px';
                playBtn.style.cursor = 'pointer';
                playBtn.style.backgroundColor = '#27ae60';
                playBtn.style.color = 'white';
                playBtn.style.border = 'none';
                playBtn.style.borderRadius = '4px';
                playBtn.onclick = () => playSentenceAudio(sentenceAudioUrl);
                containerElement.appendChild(document.createTextNode(' '));
                containerElement.appendChild(playBtn);
            }
        }

        function displayResult(data) {
            resultDiv.style.display = 'block';
            
            // Whisper Small results (present only in development UI)
            const smallText = document.getElementById('smallText');
            const smallMatch = document.getElementById('smallMatch');
            const smallTranslation = document.getElementById('smallTranslation');
            if (smallText && smallMatch && smallTranslation) {
                smallText.textContent = data.transcription_small || 'N/A';
                if (data.match_small) {
                    smallMatch.textContent = data.match_small.French || 'N/A';
                    renderNufiWithAudio(data.match_small, smallTranslation);
                    // Auto-play removed for Small model as per user request
                } else {
                    smallMatch.textContent = 'No match';
                    smallTranslation.textContent = 'N/A';
                }
            }
            
            // Whisper Medium results (present only in development UI)
            const mediumText = document.getElementById('mediumText');
            const mediumMatch = document.getElementById('mediumMatch');
            const mediumTranslation = document.getElementById('mediumTranslation');
            if (mediumText && mediumMatch && mediumTranslation) {
                mediumText.textContent = data.transcription_medium || 'N/A';
                if (data.match_medium) {
                    mediumMatch.textContent = data.match_medium.French || 'N/A';
                    renderNufiWithAudio(data.match_medium, mediumTranslation);
                    // Auto-play removed for Medium model as per user request
                } else {
                    mediumMatch.textContent = 'No match';
                    mediumTranslation.textContent = 'N/A';
                }
            }
            
            // Whisper Large-v3 results
            const largeText = document.getElementById('largeText');
            const largeMatch = document.getElementById('largeMatch');
            const largeTranslation = document.getElementById('largeTranslation');
            
            largeText.textContent = data.transcription_large || 'N/A';
            
            // Use the match provided by the backend (which is now the best hybrid match in both modes)
            const bestMatch = data.match_large;
            
            if (bestMatch) {
                largeMatch.textContent = bestMatch.French || 'N/A';
                renderNufiWithAudio(bestMatch, largeTranslation);
                
                // Auto-play logic: ONLY play for Large model match
                // Set threshold to 90% to catch excellent semantic matches like "Je suis √† l'aise" (90.5%)
                const isGoodMatch = bestMatch.match_score >= 90 && bestMatch.sentence_audio_url &&
                                   (bestMatch.match_type === 'exact' || bestMatch.match_type === 'multi-word' || bestMatch.match_type === 'semantic');
                
                if (isGoodMatch) {
                    setTimeout(() => playSentenceAudio(bestMatch.sentence_audio_url), 300);
                }
            } else {
                largeMatch.textContent = 'No match';
                largeTranslation.textContent = 'N/A';
            }
            
            // Display top 5 semantic matches in production mode
            const topMatchesSection = document.getElementById('topMatchesSection');
            const topMatchesContainer = document.getElementById('topMatchesContainer');
            if (topMatchesSection && topMatchesContainer && data.top_matches) {
                topMatchesContainer.innerHTML = ''; // Clear previous results
                
                if (data.top_matches.length > 0) {
                    data.top_matches.forEach((match, index) => {
                        const matchDiv = document.createElement('div');
                        matchDiv.style.cssText = 'background: white; padding: 10px; margin: 5px 0; border-radius: 5px; border: 1px solid #dee2e6;';
                        
                        const rank = index + 1;
                        const score = match.match_score ? match.match_score.toFixed(1) : 'N/A';
                        
                        matchDiv.innerHTML = `
                            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px;">
                                <strong style="color: #495057;">#${rank} Match (${score}% similarity)</strong>
                                <span style="font-size: 0.8em; color: #6c757d;">${match.match_type || 'semantic'}</span>
                            </div>
                            <div style="margin: 5px 0;"><strong>French:</strong> ${match.French || 'N/A'}</div>
                            <div style="margin: 5px 0;"><strong>Nufi:</strong> <span class="translation-${index}"></span></div>
                        `;
                        
                        topMatchesContainer.appendChild(matchDiv);
                        
                        // Render Nufi with audio for this match
                        const translationElement = matchDiv.querySelector(`.translation-${index}`);
                        if (translationElement) {
                            renderNufiWithAudio(match, translationElement);
                        }
                    });
                    
                    topMatchesSection.style.display = 'block';
                } else {
                    topMatchesSection.style.display = 'none';
                }
            }
            
            // Comparison section (development UI only)
            const comparisonText = document.getElementById('comparisonText');
            const small = data.transcription_small || '';
            const medium = data.transcription_medium || '';
            const large = data.transcription_large || '';
            if (comparisonText) {
                if (small.toLowerCase() === medium.toLowerCase() && medium.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚úÖ <strong>All three models agree!</strong><br>Transcription: "' + small + '"';
                    comparisonText.style.color = '#155724';
                } else if (small.toLowerCase() === medium.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Small and Medium agree</strong> (Large-v3 differs)<br>' +
                        'Small & Medium: "' + small + '"<br>' +
                        'Large-v3: "' + large + '"';
                    comparisonText.style.color = '#0c5460';
                } else if (small.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Small and Large-v3 agree</strong> (Medium differs)<br>' +
                        'Small & Large: "' + small + '"<br>' +
                        'Medium: "' + medium + '"';
                    comparisonText.style.color = '#0c5460';
                } else if (medium.toLowerCase() === large.toLowerCase()) {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Medium and Large-v3 agree</strong> (Small differs)<br>' +
                        'Small: "' + small + '"<br>' +
                        'Medium & Large: "' + medium + '"';
                    comparisonText.style.color = '#0c5460';
                } else {
                    comparisonText.innerHTML = '‚ö†Ô∏è <strong>Different results</strong><br>' +
                        'Small: "' + small + '"<br>' +
                        'Medium: "' + medium + '"<br>' +
                        'Large-v3: "' + large + '"';
                    comparisonText.style.color = '#856404';
                }
            }
            
            // Show/hide no match message
            const hasAnyMatch = data.match_small || data.match_medium || data.match_large || 
                               (data.top_matches && data.top_matches.length > 0);
            if (!hasAnyMatch) {
                document.getElementById('noMatch').style.display = 'block';
            } else {
                document.getElementById('noMatch').style.display = 'none';
            }
        }
    </script>
</body>
</html>
